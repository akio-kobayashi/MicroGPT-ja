{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MicroGPT 入門ノート（日本語版）\n",
        "\n",
        "このノートブックは、わずか数百行で書かれた最小構成の GPT 実装を **初学者向け** に学ぶ教材です。\n",
        "学習・推論を実行しながら、損失や確率分布を可視化して動作を理解します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 謝辞\n",
        "\n",
        "この教材は Andrej Karpathy 氏の MicroGPT 実装をもとに、教育目的で日本語化・可視化を追加したものです。\n",
        "\n",
        "- Original: https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95\n",
        "- Author: @karpathy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 実行準備\n",
        "Colab ではそのまま動きます。必要なら以下を実行してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip -q install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "from typing import List\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 日本語サンプルデータ（self-contained）\n",
        "外部ファイルなしで学べるよう、簡単な日本語（ひらがな・カタカナ）サンプルを内蔵しています。\n",
        "\n",
        "必要に応じて `docs` を増やしてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = [\n",
        "    \"さくら\", \"すず\", \"はる\", \"ひなた\", \"みお\",\n",
        "    \"ゆい\", \"あかり\", \"りん\", \"あおい\", \"めい\",\n",
        "    \"たくみ\", \"そうた\", \"けん\", \"れん\", \"だいき\",\n",
        "    \"しょう\", \"こうた\", \"はると\", \"ゆう\", \"なお\",\n",
        "    \"サクラ\", \"ユイ\", \"アオイ\", \"レン\", \"ハルト\",\n",
        "    \"しおり\", \"かな\", \"まな\", \"りお\", \"えま\",\n",
        "]\n",
        "random.shuffle(docs)\n",
        "print(f\"文書数: {len(docs)}\")\n",
        "print(\"サンプル:\", docs[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. トークナイザ（文字単位）\n",
        "この最小実装では単語ではなく **1文字ずつ** をトークンとして扱います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "uchars = sorted(set(''.join(docs)))\n",
        "BOS = len(uchars)\n",
        "vocab_size = len(uchars) + 1\n",
        "\n",
        "stoi = {ch: i for i, ch in enumerate(uchars)}\n",
        "itos = {i: ch for ch, i in stoi.items()}\n",
        "itos[BOS] = \"<BOS>\"\n",
        "\n",
        "print(f\"語彙数(vocab_size): {vocab_size}\")\n",
        "print(\"語彙:\", ''.join(uchars))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 自動微分 Value クラス\n",
        "各値が『どの計算から生まれたか』を覚えておき、最後に `backward()` で勾配を逆伝播します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Value:\n",
        "    __slots__ = ('data', 'grad', '_children', '_local_grads')\n",
        "\n",
        "    def __init__(self, data, children=(), local_grads=()):\n",
        "        # 順伝播で得られる実数値\n",
        "        self.data = data\n",
        "        # 逆伝播で蓄積される勾配\n",
        "        self.grad = 0\n",
        "        # 計算グラフ上の親ノード\n",
        "        self._children = children\n",
        "        # 親に対する局所勾配\n",
        "        self._local_grads = local_grads\n",
        "\n",
        "    def __add__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        return Value(self.data + other.data, (self, other), (1, 1))\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        return Value(self.data * other.data, (self, other), (other.data, self.data))\n",
        "\n",
        "    def __pow__(self, other):\n",
        "        return Value(self.data ** other, (self,), (other * self.data ** (other - 1),))\n",
        "\n",
        "    def log(self):\n",
        "        return Value(math.log(self.data), (self,), (1 / self.data,))\n",
        "\n",
        "    def exp(self):\n",
        "        return Value(math.exp(self.data), (self,), (math.exp(self.data),))\n",
        "\n",
        "    def relu(self):\n",
        "        return Value(max(0, self.data), (self,), (float(self.data > 0),))\n",
        "\n",
        "    def __neg__(self): return self * -1\n",
        "    def __radd__(self, other): return self + other\n",
        "    def __sub__(self, other): return self + (-other)\n",
        "    def __rsub__(self, other): return other + (-self)\n",
        "    def __rmul__(self, other): return self * other\n",
        "    def __truediv__(self, other): return self * other ** -1\n",
        "    def __rtruediv__(self, other): return other * self ** -1\n",
        "\n",
        "    def backward(self):\n",
        "        # 計算グラフをトポロジカル順序に並べる\n",
        "        topo = []\n",
        "        visited = set()\n",
        "\n",
        "        def build_topo(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v._children:\n",
        "                    build_topo(child)\n",
        "                topo.append(v)\n",
        "\n",
        "        build_topo(self)\n",
        "        self.grad = 1\n",
        "\n",
        "        # 逆順にたどって勾配を伝播\n",
        "        for v in reversed(topo):\n",
        "            for child, local_grad in zip(v._children, v._local_grads):\n",
        "                child.grad += local_grad * v.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. モデル定義（ミニGPT）\n",
        "計算量を抑えるため、教育向けの小さな設定を使います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== ハイパーパラメータ =====\n",
        "n_embd = 16\n",
        "n_head = 4\n",
        "n_layer = 1\n",
        "block_size = 16\n",
        "head_dim = n_embd // n_head\n",
        "\n",
        "def matrix(nout, nin, std=0.08):\n",
        "    return [[Value(random.gauss(0, std)) for _ in range(nin)] for _ in range(nout)]\n",
        "\n",
        "state_dict = {\n",
        "    'wte': matrix(vocab_size, n_embd),\n",
        "    'wpe': matrix(block_size, n_embd),\n",
        "    'lm_head': matrix(vocab_size, n_embd),\n",
        "}\n",
        "\n",
        "for i in range(n_layer):\n",
        "    state_dict[f'layer{i}.attn_wq'] = matrix(n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.attn_wk'] = matrix(n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.attn_wv'] = matrix(n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.attn_wo'] = matrix(n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.mlp_fc1'] = matrix(4 * n_embd, n_embd)\n",
        "    state_dict[f'layer{i}.mlp_fc2'] = matrix(n_embd, 4 * n_embd)\n",
        "\n",
        "params = [p for mat in state_dict.values() for row in mat for p in row]\n",
        "print(f\"パラメータ数: {len(params)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear(x, w):\n",
        "    return [sum(wi * xi for wi, xi in zip(wo, x)) for wo in w]\n",
        "\n",
        "def softmax(logits):\n",
        "    max_val = max(val.data for val in logits)\n",
        "    exps = [(val - max_val).exp() for val in logits]\n",
        "    total = sum(exps)\n",
        "    return [e / total for e in exps]\n",
        "\n",
        "def rmsnorm(x):\n",
        "    ms = sum(xi * xi for xi in x) / len(x)\n",
        "    scale = (ms + 1e-5) ** -0.5\n",
        "    return [xi * scale for xi in x]\n",
        "\n",
        "def gpt(token_id, pos_id, keys, values):\n",
        "    tok_emb = state_dict['wte'][token_id]\n",
        "    pos_emb = state_dict['wpe'][pos_id]\n",
        "    x = [t + p for t, p in zip(tok_emb, pos_emb)]\n",
        "    x = rmsnorm(x)\n",
        "\n",
        "    for li in range(n_layer):\n",
        "        x_residual = x\n",
        "        x = rmsnorm(x)\n",
        "        q = linear(x, state_dict[f'layer{li}.attn_wq'])\n",
        "        k = linear(x, state_dict[f'layer{li}.attn_wk'])\n",
        "        v = linear(x, state_dict[f'layer{li}.attn_wv'])\n",
        "        keys[li].append(k)\n",
        "        values[li].append(v)\n",
        "\n",
        "        x_attn = []\n",
        "        for h in range(n_head):\n",
        "            hs = h * head_dim\n",
        "            q_h = q[hs:hs + head_dim]\n",
        "            k_h = [ki[hs:hs + head_dim] for ki in keys[li]]\n",
        "            v_h = [vi[hs:hs + head_dim] for vi in values[li]]\n",
        "\n",
        "            attn_logits = [\n",
        "                sum(q_h[j] * k_h[t][j] for j in range(head_dim)) / head_dim ** 0.5\n",
        "                for t in range(len(k_h))\n",
        "            ]\n",
        "            attn_weights = softmax(attn_logits)\n",
        "            head_out = [\n",
        "                sum(attn_weights[t] * v_h[t][j] for t in range(len(v_h)))\n",
        "                for j in range(head_dim)\n",
        "            ]\n",
        "            x_attn.extend(head_out)\n",
        "\n",
        "        x = linear(x_attn, state_dict[f'layer{li}.attn_wo'])\n",
        "        x = [a + b for a, b in zip(x, x_residual)]\n",
        "\n",
        "        x_residual = x\n",
        "        x = rmsnorm(x)\n",
        "        x = linear(x, state_dict[f'layer{li}.mlp_fc1'])\n",
        "        x = [xi.relu() for xi in x]\n",
        "        x = linear(x, state_dict[f'layer{li}.mlp_fc2'])\n",
        "        x = [a + b for a, b in zip(x, x_residual)]\n",
        "\n",
        "    logits = linear(x, state_dict['lm_head'])\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 学習\n",
        "学習ログを保存し、あとで損失曲線を描きます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate, beta1, beta2, eps_adam = 0.01, 0.85, 0.99, 1e-8\n",
        "m = [0.0] * len(params)\n",
        "v = [0.0] * len(params)\n",
        "\n",
        "num_steps = 600\n",
        "loss_history: List[float] = []\n",
        "\n",
        "for step in range(num_steps):\n",
        "    doc = docs[step % len(docs)]\n",
        "    tokens = [BOS] + [stoi[ch] for ch in doc] + [BOS]\n",
        "    n = min(block_size, len(tokens) - 1)\n",
        "\n",
        "    keys, values = [[] for _ in range(n_layer)], [[] for _ in range(n_layer)]\n",
        "    losses = []\n",
        "    for pos_id in range(n):\n",
        "        token_id, target_id = tokens[pos_id], tokens[pos_id + 1]\n",
        "        logits = gpt(token_id, pos_id, keys, values)\n",
        "        probs = softmax(logits)\n",
        "        loss_t = -probs[target_id].log()\n",
        "        losses.append(loss_t)\n",
        "\n",
        "    loss = (1 / n) * sum(losses)\n",
        "    loss.backward()\n",
        "\n",
        "    lr_t = learning_rate * (1 - step / num_steps)\n",
        "    for i, p in enumerate(params):\n",
        "        m[i] = beta1 * m[i] + (1 - beta1) * p.grad\n",
        "        v[i] = beta2 * v[i] + (1 - beta2) * p.grad ** 2\n",
        "        m_hat = m[i] / (1 - beta1 ** (step + 1))\n",
        "        v_hat = v[i] / (1 - beta2 ** (step + 1))\n",
        "        p.data -= lr_t * m_hat / (v_hat ** 0.5 + eps_adam)\n",
        "        p.grad = 0\n",
        "\n",
        "    loss_history.append(loss.data)\n",
        "\n",
        "    if (step + 1) % 50 == 0:\n",
        "        print(f\"step {step+1:4d}/{num_steps} | loss={loss.data:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(loss_history, label='train loss')\n",
        "plt.title('学習損失の推移')\n",
        "plt.xlabel('step')\n",
        "plt.ylabel('loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 推論（新しい名前を生成）\n",
        "温度 `temperature` を上げると多様性が増え、下げると安定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_one(temperature=0.8, max_len=block_size):\n",
        "    keys, values = [[] for _ in range(n_layer)], [[] for _ in range(n_layer)]\n",
        "    token_id = BOS\n",
        "    out = []\n",
        "\n",
        "    for pos_id in range(max_len):\n",
        "        logits = gpt(token_id, pos_id, keys, values)\n",
        "        probs = softmax([l / temperature for l in logits])\n",
        "        token_id = random.choices(range(vocab_size), weights=[p.data for p in probs])[0]\n",
        "        if token_id == BOS:\n",
        "            break\n",
        "        out.append(itos[token_id])\n",
        "\n",
        "    return ''.join(out)\n",
        "\n",
        "for i in range(12):\n",
        "    print(f\"sample {i+1:2d}: {sample_one(temperature=0.7)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 可視化: 次トークン確率 Top-10\n",
        "先頭トークン（`<BOS>`）から1文字目として何が出やすいかを棒グラフで確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "keys, values = [[] for _ in range(n_layer)], [[] for _ in range(n_layer)]\n",
        "logits = gpt(BOS, 0, keys, values)\n",
        "probs = softmax(logits)\n",
        "prob_values = [p.data for p in probs]\n",
        "\n",
        "topk = 10\n",
        "top_ids = sorted(range(vocab_size), key=lambda i: prob_values[i], reverse=True)[:topk]\n",
        "top_labels = [itos[i] for i in top_ids]\n",
        "top_probs = [prob_values[i] for i in top_ids]\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(top_labels, top_probs)\n",
        "plt.title('次トークン確率 Top-10 (開始トークンから)')\n",
        "plt.xlabel('トークン')\n",
        "plt.ylabel('確率')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "for t, p in zip(top_labels, top_probs):\n",
        "    print(f\"{t:>5}: {p:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "MicroGPT_ja_colab.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
